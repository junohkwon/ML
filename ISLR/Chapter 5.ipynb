{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Load dataset](#Load-dataset)\n",
    "- [Cross-Validation](#5.1-Cross-Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset available on http://www-bcf.usc.edu/~gareth/ISL/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Data/Auto.csv', na_values='?').dropna()\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5.2 - Validation Set Approach\n",
    "Using Polynomial feature generation in scikit-learn<BR>\n",
    "http://scikit-learn.org/dev/modules/preprocessing.html#generating-polynomial-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_prop = 0.5\n",
    "p_order = np.arange(1,11)\n",
    "r_state = np.arange(0,10)\n",
    "\n",
    "X, Y = np.meshgrid(p_order, r_state, indexing='ij')\n",
    "Z = np.zeros((p_order.size,r_state.size))\n",
    "\n",
    "regr = skl_lm.LinearRegression()\n",
    "\n",
    "# Generate 10 random splits of the dataset\n",
    "for (i,j),v in np.ndenumerate(Z):\n",
    "    poly = PolynomialFeatures(int(X[i,j]))\n",
    "    X_poly = poly.fit_transform(df1.horsepower.values.reshape(-1,1))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, df1.mpg.ravel(),\n",
    "                                                        test_size=t_prop, random_state=Y[i,j])\n",
    "                                                                        \n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_test)\n",
    "    Z[i,j]= mean_squared_error(y_test, pred)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Left plot (first split)\n",
    "ax1.plot(X.T[0],Z.T[0], '-o')\n",
    "ax1.set_title('Random split of the data set')\n",
    "\n",
    "# Right plot (all splits)\n",
    "ax2.plot(X,Z)\n",
    "ax2.set_title('10 random splits of the data set')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.set_ylabel('Mean Squared Error')\n",
    "    ax.set_ylim(15,30)\n",
    "    ax.set_xlabel('Degree of Polynomial')\n",
    "    ax.set_xlim(0.5,10.5)\n",
    "    ax.set_xticks(range(2,11,2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_order = np.arange(1,11)\n",
    "r_state = np.arange(0,10)\n",
    "\n",
    "# LeaveOneOut CV\n",
    "regr = skl_lm.LinearRegression()\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(df1)\n",
    "scores = list()\n",
    "\n",
    "for i in p_order:\n",
    "    poly = PolynomialFeatures(i)\n",
    "    X_poly = poly.fit_transform(df1.horsepower.values.reshape(-1,1))\n",
    "    score = cross_val_score(regr, X_poly, df1.mpg, cv=loo, scoring='neg_mean_squared_error').mean()\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold CV\n",
    "folds = 10\n",
    "elements = len(df1.index)\n",
    "\n",
    "X, Y = np.meshgrid(p_order, r_state, indexing='ij')\n",
    "Z = np.zeros((p_order.size,r_state.size))\n",
    "\n",
    "regr = skl_lm.LinearRegression()\n",
    "\n",
    "for (i,j),v in np.ndenumerate(Z):\n",
    "    poly = PolynomialFeatures(X[i,j])\n",
    "    X_poly = poly.fit_transform(df1.horsepower.values.reshape(-1,1))\n",
    "    kf_10 = KFold(n_splits=folds, random_state=Y[i,j])\n",
    "    Z[i,j] = cross_val_score(regr, X_poly, df1.mpg, cv=kf_10, scoring='neg_mean_squared_error').mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Note: cross_val_score() method return negative values for the scores.\n",
    "# https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "\n",
    "# Left plot\n",
    "ax1.plot(p_order, np.array(scores)*-1, '-o')\n",
    "ax1.set_title('LOOCV')\n",
    "\n",
    "# Right plot\n",
    "ax2.plot(X,Z*-1)\n",
    "ax2.set_title('10-fold CV')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.set_ylabel('Mean Squared Error')\n",
    "    ax.set_ylim(15,30)\n",
    "    ax.set_xlabel('Degree of Polynomial')\n",
    "    ax.set_xlim(0.5,10.5)\n",
    "    ax.set_xticks(range(2,11,2));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
