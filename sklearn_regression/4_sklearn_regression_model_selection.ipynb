{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Regression - Model Selection\n",
    "작성자: 고정훈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn 홈페이지를 둘러보시면 정말 많은 Regression/Classification 알고리즘이 있습니다. 각 알고리즘은 저마다의 장단점이 있습니다. 데이터별로 궁합도 따져봐야 합니다. 하나의 알고리즘으로 모든 걸 해결 할 수 있다면 그 많은 알고리즘이 필요하지 않을 것입니다. \n",
    "\n",
    "알고리즘 선택이 끝이 아닙니다. 한 알고리즘 안에서도 Hyper-parameter를 어떻게 선택하느냐에 따라서 결과는 달라집니다. Neural Network를 사용하는 `MLPRegressor`은 hyper-parameter를 사용하는 것이 매우 중요합니다. \n",
    "\n",
    "끝이 아닙니다. 전처리(Preprocessing)을 어떻게 하느냐도 중요합니다. Min/Max scaling과 Standard Scaling 중 어느 쪽이 더 좋을지, Feature selection을 해야 하는지, 한다면 어떤 방법론을 써야 하는지, 차원 축소는 얼마나 해야할지 이 모든 것이 데이터에 따라 다르고, 함께 사용하는 학습 알고리즘에 따라 다릅니다. \n",
    "\n",
    "(전처리를 포함하여) 알고리즘을 무엇을 선택하고 hyper-parameter는 어떻게 선택할지 동시에 최적화 하는 문제를 CASH(Combined Algorithm Selection and Hyper-parameter optimization) Problem이라고 합니다. \n",
    "\n",
    "Model을 고를 수 있는 경우의 수가 많고, 성능과의 관계가 복잡하기 때문에, 많은 시도를 통해 찾아야 합니다. 이런 경우에 Baesian Optimization을 활용하면 좋긴하지만 Scikit-learn에서는 아직 지원하지 않습니다(2018년 4월 기준).\n",
    "\n",
    "대신 Grid Search와 Random Search 방법을 제공합니다. Bayesian search는 병렬계산이 제한적이지만 Grid Search와 Random Search는 병렬화가 가능하기 때문에 자원이 풍부할 때는 충분히 좋은 결과를 만들어낼 수 있습니다. 다만 hyper-parameter optimization은 가능하지만 Algorithm Selection은 매뉴얼로 작업해야 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "흔들어보고 싶은 hyper-parameter가 a, b라고 가정하겠습니다. a는 [1, 2, 3], b는 [10, 20, 30]을 각각 시도해보고 싶다면 Grid Search 는 a와 b의 가능한 모든 조합에 대해 다 시도해보는 것을 의미합니다. \n",
    "\n",
    "(1, 10), (2, 10), (3, 10), (1, 20), (2, 20), (3, 20), (1, 30), (2, 30), (3, 30)을 다 시도해보는 것이죠.\n",
    "\n",
    "만약 흔들어 보고 싶은 hyper-parameter가 다수이고, 각각 많은 시도를 해보고 싶을 때는 그 조합 수가 무척 많아질 것입니다. Grid Search는 흔들 hyper-parameter 개수가 적거나, 한 hyper-parameter 내에서 흔들어 볼 후보 수가 적을 때 사용하는 것이 좋습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.372839693968\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "x, y =load_diabetes(return_X_y=True)\n",
    "y = np.reshape(y, (-1, 1))\n",
    "x = StandardScaler().fit_transform(x)  \n",
    "y = StandardScaler().fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)\n",
    "\n",
    "regressor = MLPRegressor(max_iter=3000, random_state=2)  # Multi-layer perceptron을 정의합니다.\n",
    "\n",
    "param_grid = {'hidden_layer_sizes': [(10,), (20,), (30,), (10, 10)],\n",
    "              'solver': ['adam', 'lbfgs']\n",
    "              }  # parameter를 흔들 space를 정의합니다.\n",
    "\n",
    "gs = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=KFold(shuffle=True), refit=True)  # Grid Search를 initialization 합니다.\n",
    "gs.fit(x_train, y_train.ravel())  # hyper-parameter를 흔들어가며 최적의 hyper-parameter를 찾습니다. refit=True이기 때문에 찾은 모델에 대해 전체 데이터로 다시 학습합니다.  \n",
    "score = gs.score(x_test, y_test.ravel())  # Test score를 계산해봅니다. \n",
    "print('Score:', score)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV`는 *param_grid*에 입력된 parameter space의 모든 조합에 대해 내부적으로 cross validation을 진행한 후 가장 성능이 좋은 hyper-parameter를 찾아 전체 데이터에 대해서 다시 학습합니다. \n",
    "\n",
    "어떤 hyper-parameter 조합을 최적으로 찾았는지 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (30,), 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV`로 `predict`, `score`등 estimator가 수행하는 method를 그대로 사용할 수 있습니다. 가장 성능이 좋은 모델을 기준으로 수행하는 것이죠. 만약 best model을 끄집어내고 싶으시다면 아래와 같이 하시면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(30,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=3000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=2, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "regressor = gs.best_estimator_\n",
    "print(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자세한 탐색 결과를 알고 싶다면 아래 attribute를 불러오면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0       0.168785         0.000000         0.488294          0.569908   \n",
      "1       0.457323         0.000000         0.079410          0.832664   \n",
      "2       0.113080         0.000334         0.493556          0.610789   \n",
      "3       0.973021         0.000000        -1.202203          0.992400   \n",
      "4       0.159111         0.000668         0.499207          0.638202   \n",
      "5       0.458325         0.000000        -1.370984          0.999989   \n",
      "6       0.185798         0.000334         0.430692          0.604212   \n",
      "7       1.010047         0.000000        -0.959507          0.954842   \n",
      "\n",
      "  param_hidden_layer_sizes param_solver  \\\n",
      "0                    (10,)         adam   \n",
      "1                    (10,)        lbfgs   \n",
      "2                    (20,)         adam   \n",
      "3                    (20,)        lbfgs   \n",
      "4                    (30,)         adam   \n",
      "5                    (30,)        lbfgs   \n",
      "6                 (10, 10)         adam   \n",
      "7                 (10, 10)        lbfgs   \n",
      "\n",
      "                                              params  rank_test_score  \\\n",
      "0    {'hidden_layer_sizes': (10,), 'solver': 'adam'}                3   \n",
      "1   {'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}                5   \n",
      "2    {'hidden_layer_sizes': (20,), 'solver': 'adam'}                2   \n",
      "3   {'hidden_layer_sizes': (20,), 'solver': 'lbfgs'}                7   \n",
      "4    {'hidden_layer_sizes': (30,), 'solver': 'adam'}                1   \n",
      "5   {'hidden_layer_sizes': (30,), 'solver': 'lbfgs'}                8   \n",
      "6  {'hidden_layer_sizes': (10, 10), 'solver': 'ad...                4   \n",
      "7  {'hidden_layer_sizes': (10, 10), 'solver': 'lb...                6   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0           0.435709            0.580487           0.508196   \n",
      "1           0.128678            0.846001           0.167683   \n",
      "2           0.449375            0.651414           0.464847   \n",
      "3          -1.136316            0.994636          -0.944893   \n",
      "4           0.445833            0.684876           0.515421   \n",
      "5          -0.650180            0.999990          -1.821275   \n",
      "6           0.378725            0.628055           0.491628   \n",
      "7          -0.195720            0.978406          -1.601307   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0            0.566297           0.521456            0.562939      0.009680   \n",
      "1            0.830677          -0.058578            0.821314      0.185497   \n",
      "2            0.590057           0.566848            0.590897      0.007794   \n",
      "3            0.990405          -1.526000            0.992159      0.130097   \n",
      "4            0.611539           0.536852            0.618192      0.008293   \n",
      "5            0.999985          -1.648050            0.999992      0.099846   \n",
      "6            0.588019           0.422196            0.596561      0.013970   \n",
      "7            0.958121          -1.088438            0.927999      0.132825   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "0        0.000000        0.037741         0.007605  \n",
      "1        0.000000        0.098647         0.010176  \n",
      "2        0.000472        0.052093         0.028728  \n",
      "3        0.000000        0.241457         0.001735  \n",
      "4        0.000944        0.038906         0.033115  \n",
      "5        0.000000        0.516843         0.000003  \n",
      "6        0.000472        0.046515         0.017217  \n",
      "7        0.000000        0.581415         0.020709  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cv_result = pd.DataFrame(gs.cv_results_)\n",
    "print(cv_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search는 탐색 공간(search space)에서 무작위로 hyper-parameter를 추출합니다. Grid Search가 정해놓은 값 중들의 조합을 모두 시도한다면, Random Search는 정해준 구간 내에서 정해준 시도 횟수만큼 hyper-parameter를 테스트합니다. \n",
    "\n",
    "Random Search의 장점은 시도해볼 hyper-parameter가 많아도 search가 가능하며, <U>의외로 결과가 좋다는 것입니다</U>. 얼핏 생각하면 무작위로 hyper-parameter 조합을 만들면 최적을 우연히 찾기 쉽지 않을 것 같습니다. 한 가지 정답이 있는 것이 아니라 다양한 조합이 최적에 가까운(sub-optimal) 결과를 만들어내기 때문에 random search를 통해서도 의미있는 결과를 만들어 낼 수 있습니다. \n",
    "\n",
    "Random Search와 대변되는 것이 Bayesian Optimization입니다. Bayesian은 sequential하게 다음 모델을 고르기 때문에 병렬화가 불가능하지만,  Random Search는 서로가 무관한 trial이기 때문에 하드웨어가 허락하는만큼 동시에 여러 모델을 시도해볼 수 있는 장점 또한 있습니다. \n",
    "\n",
    "Scikit-learn에서는 RandomizedSearchCV를 이용해 random search를 할 수 있습니다. 사용법은 GridSearchCV와 거의 유사하나 parameter space를 만드는 방법만 다릅니다. \n",
    "\n",
    "RandomizedSearchCV에서는 GridSearchCV에서처럼 list안에 후보 변수들을 입력할 필요 없습니다. 특정 분포로부터 뽑아내게 할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.390698125197\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "param_dist = {'hidden_layer_sizes': [(n_node,) for n_node in range(5, 31)],\n",
    "              'solver': ['adam', 'lbfgs'],\n",
    "              'alpha': uniform(0.0001, 0.005),\n",
    "              'max_iter': randint(1000, 5001),\n",
    "              } # parameter를 흔들 space를 정의합니다.\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=regressor, \n",
    "                        param_distributions=param_dist, \n",
    "                        n_iter=30,\n",
    "                        cv=KFold(shuffle=True), \n",
    "                        refit=True,\n",
    "                        random_state=2)  # Random Search를 initialization 합니다.\n",
    "rs.fit(x_train, y_train.ravel())  # hyper-parameter를 흔들어가며 최적의 hyper-parameter를 찾습니다. refit=True이기 때문에 찾은 모델에 대해 전체 데이터로 다시 학습합니다.  \n",
    "score = rs.score(x_test, y_test.ravel())  # Test score를 계산해봅니다. \n",
    "print('Score:', score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (14,), 'alpha': 0.00069742399164656518, 'max_iter': 1366, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0        0.178464         0.000334         0.501589          0.597321   \n",
      "1        0.991696         0.000667        -0.329965          0.933950   \n",
      "2        0.601091         0.000000        -0.452470          0.929060   \n",
      "3        0.121747         0.000334         0.445352          0.601867   \n",
      "4        0.220159         0.000333         0.468094          0.558121   \n",
      "5        0.116074         0.000000         0.481407          0.603741   \n",
      "6        0.226826         0.000334         0.468138          0.558137   \n",
      "7        0.621439         0.000333        -0.203778          0.878229   \n",
      "8        0.208147         0.000333         0.484295          0.568705   \n",
      "9        0.099404         0.000000         0.497956          0.607318   \n",
      "10       0.739522         0.000667        -1.009655          0.994912   \n",
      "11       0.098736         0.000667         0.497941          0.607310   \n",
      "12       0.468331         0.000000        -1.090018          0.971120   \n",
      "13       0.531708         0.000334        -0.947755          0.999991   \n",
      "14       0.145102         0.000000         0.509408          0.612239   \n",
      "15       0.391609         0.000333        -0.914701          0.995386   \n",
      "16       0.097069         0.000667         0.498015          0.607306   \n",
      "17       0.191802         0.000000         0.471625          0.593553   \n",
      "18       0.149439         0.000334         0.498763          0.554830   \n",
      "19       0.995370         0.001000        -0.726689          0.999984   \n",
      "20       0.137430         0.000667         0.497008          0.610098   \n",
      "21       0.152440         0.000334         0.498688          0.554690   \n",
      "22       0.727513         0.000334        -0.698667          0.999943   \n",
      "23       0.744526         0.000000        -0.508515          0.932597   \n",
      "24       1.065085         0.000667        -1.500782          0.996625   \n",
      "25       0.129758         0.000333         0.493698          0.618665   \n",
      "26       0.131760         0.000334         0.496989          0.610135   \n",
      "27       0.584746         0.000334        -0.073721          0.860311   \n",
      "28       0.446648         0.000334        -0.981571          0.999393   \n",
      "29       0.306883         0.000667         0.352542          0.478338   \n",
      "\n",
      "    param_alpha param_hidden_layer_sizes param_max_iter param_solver  \\\n",
      "0    0.00227997                    (18,)           2608         adam   \n",
      "1    0.00483865                    (16,)           3408        lbfgs   \n",
      "2    0.00175167                    (16,)           3773        lbfgs   \n",
      "3    0.00159827                    (25,)           1124         adam   \n",
      "4    0.00274571                     (8,)           2126         adam   \n",
      "5    0.00303398                    (24,)           3407         adam   \n",
      "6    0.00436988                     (8,)           2349         adam   \n",
      "7    0.00262623                    (11,)           2375        lbfgs   \n",
      "8   0.000680967                     (7,)           4664         adam   \n",
      "9    0.00308373                    (23,)           1132         adam   \n",
      "10   0.00393746                    (22,)           2831        lbfgs   \n",
      "11   0.00243894                    (23,)           4565         adam   \n",
      "12   0.00337133                    (18,)           1392        lbfgs   \n",
      "13   0.00203446                    (29,)           3554        lbfgs   \n",
      "14  0.000697424                    (14,)           1366         adam   \n",
      "15   0.00492276                    (24,)           1096        lbfgs   \n",
      "16   0.00506633                    (23,)           3952         adam   \n",
      "17   0.00223773                    (13,)           3082         adam   \n",
      "18   0.00243921                    (10,)           1838         adam   \n",
      "19   0.00282104                    (29,)           4538        lbfgs   \n",
      "20   0.00421442                    (22,)           2085         adam   \n",
      "21  0.000236012                    (10,)           1609         adam   \n",
      "22   0.00454152                    (28,)           1918        lbfgs   \n",
      "23   0.00410129                    (15,)           3266        lbfgs   \n",
      "24  0.000946127                    (21,)           4895        lbfgs   \n",
      "25   0.00188312                    (21,)           1424         adam   \n",
      "26   0.00230677                    (22,)           3703         adam   \n",
      "27   0.00139872                    (12,)           4903        lbfgs   \n",
      "28   0.00378374                    (27,)           1187        lbfgs   \n",
      "29   0.00187877                     (5,)           2598         adam   \n",
      "\n",
      "                                               params  rank_test_score  \\\n",
      "0   {'hidden_layer_sizes': (18,), 'alpha': 0.00227...                2   \n",
      "1   {'hidden_layer_sizes': (16,), 'alpha': 0.00483...               20   \n",
      "2   {'hidden_layer_sizes': (16,), 'alpha': 0.00175...               21   \n",
      "3   {'hidden_layer_sizes': (25,), 'alpha': 0.00159...               16   \n",
      "4   {'hidden_layer_sizes': (8,), 'alpha': 0.002745...               15   \n",
      "5   {'hidden_layer_sizes': (24,), 'alpha': 0.00303...               12   \n",
      "6   {'hidden_layer_sizes': (8,), 'alpha': 0.004369...               14   \n",
      "7   {'hidden_layer_sizes': (11,), 'alpha': 0.00262...               19   \n",
      "8   {'hidden_layer_sizes': (7,), 'alpha': 0.000680...               11   \n",
      "9   {'hidden_layer_sizes': (23,), 'alpha': 0.00308...                6   \n",
      "10  {'hidden_layer_sizes': (22,), 'alpha': 0.00393...               28   \n",
      "11  {'hidden_layer_sizes': (23,), 'alpha': 0.00243...                7   \n",
      "12  {'hidden_layer_sizes': (18,), 'alpha': 0.00337...               29   \n",
      "13  {'hidden_layer_sizes': (29,), 'alpha': 0.00203...               26   \n",
      "14  {'hidden_layer_sizes': (14,), 'alpha': 0.00069...                1   \n",
      "15  {'hidden_layer_sizes': (24,), 'alpha': 0.00492...               25   \n",
      "16  {'hidden_layer_sizes': (23,), 'alpha': 0.00506...                5   \n",
      "17  {'hidden_layer_sizes': (13,), 'alpha': 0.00223...               13   \n",
      "18  {'hidden_layer_sizes': (10,), 'alpha': 0.00243...                3   \n",
      "19  {'hidden_layer_sizes': (29,), 'alpha': 0.00282...               24   \n",
      "20  {'hidden_layer_sizes': (22,), 'alpha': 0.00421...                8   \n",
      "21  {'hidden_layer_sizes': (10,), 'alpha': 0.00023...                4   \n",
      "22  {'hidden_layer_sizes': (28,), 'alpha': 0.00454...               23   \n",
      "23  {'hidden_layer_sizes': (15,), 'alpha': 0.00410...               22   \n",
      "24  {'hidden_layer_sizes': (21,), 'alpha': 0.00094...               30   \n",
      "25  {'hidden_layer_sizes': (21,), 'alpha': 0.00188...               10   \n",
      "26  {'hidden_layer_sizes': (22,), 'alpha': 0.00230...                9   \n",
      "27  {'hidden_layer_sizes': (12,), 'alpha': 0.00139...               18   \n",
      "28  {'hidden_layer_sizes': (27,), 'alpha': 0.00378...               27   \n",
      "29  {'hidden_layer_sizes': (5,), 'alpha': 0.001878...               17   \n",
      "\n",
      "    split0_test_score  split0_train_score  split1_test_score  \\\n",
      "0            0.507686            0.590301           0.488876   \n",
      "1           -0.493470            0.937448          -0.236903   \n",
      "2           -0.465458            0.930033          -0.333778   \n",
      "3            0.452885            0.567970           0.452642   \n",
      "4            0.489531            0.559873           0.418672   \n",
      "5            0.504237            0.611411           0.482783   \n",
      "6            0.489551            0.559875           0.418762   \n",
      "7            0.043876            0.861836          -0.312035   \n",
      "8            0.425135            0.557449           0.545869   \n",
      "9            0.507380            0.587161           0.485288   \n",
      "10          -0.606886            0.995133          -0.709484   \n",
      "11           0.507388            0.587146           0.485291   \n",
      "12          -1.460116            0.966644          -0.555889   \n",
      "13          -1.030131            0.999991          -0.571257   \n",
      "14           0.561908            0.617571           0.496572   \n",
      "15          -0.654845            0.993271          -0.518100   \n",
      "16           0.507431            0.587133           0.485328   \n",
      "17           0.503716            0.573386           0.485756   \n",
      "18           0.493093            0.546574           0.496849   \n",
      "19          -0.623755            0.999983          -0.521686   \n",
      "20           0.543067            0.592540           0.472114   \n",
      "21           0.493057            0.546304           0.496855   \n",
      "22          -0.566933            0.999962          -1.140780   \n",
      "23          -0.507329            0.925557          -0.202098   \n",
      "24          -1.857052            0.996930          -1.149786   \n",
      "25           0.513441            0.590193           0.489631   \n",
      "26           0.543107            0.592573           0.472121   \n",
      "27           0.092606            0.815363          -0.000693   \n",
      "28          -0.986362            0.998481          -0.660472   \n",
      "29           0.310513            0.458967           0.398209   \n",
      "\n",
      "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "0             0.615701           0.508150            0.585962      0.021555   \n",
      "1             0.927167          -0.258035            0.937235      0.079162   \n",
      "2             0.920187          -0.558058            0.936960      0.294109   \n",
      "3             0.614421           0.430460            0.623210      0.017526   \n",
      "4             0.548427           0.495884            0.566063      0.024733   \n",
      "5             0.597736           0.456994            0.602076      0.027671   \n",
      "6             0.548468           0.495908            0.566067      0.037347   \n",
      "7             0.892386          -0.345429            0.880465      0.039534   \n",
      "8             0.572790           0.482421            0.575874      0.033200   \n",
      "9             0.623594           0.501115            0.611200      0.009884   \n",
      "10            0.992632          -1.716257            0.996970      0.185950   \n",
      "11            0.623578           0.501058            0.611206      0.011565   \n",
      "12            0.968472          -1.250684            0.978244      0.008047   \n",
      "13            0.999993          -1.241127            0.999990      0.078734   \n",
      "14            0.601495           0.469265            0.617650      0.036366   \n",
      "15            0.995805          -1.573519            0.997083      0.002627   \n",
      "16            0.623582           0.501199            0.611204      0.008292   \n",
      "17            0.572232           0.425113            0.635041      0.040791   \n",
      "18            0.563752           0.506400            0.554164      0.008184   \n",
      "19            0.999983          -1.035563            0.999987      0.124754   \n",
      "20            0.590609           0.475424            0.647144      0.034898   \n",
      "21            0.563732           0.506203            0.554035      0.006187   \n",
      "22            0.999896          -0.389487            0.999971      0.009098   \n",
      "23            0.927382          -0.816127            0.944852      0.185918   \n",
      "24            0.996091          -1.492270            0.996853      0.054825   \n",
      "25            0.628374           0.477844            0.637427      0.026418   \n",
      "26            0.590619           0.475318            0.647212      0.030891   \n",
      "27            0.873000          -0.314587            0.892571      0.157516   \n",
      "28            0.999839          -1.297836            0.999860      0.004193   \n",
      "29            0.475316           0.349285            0.500731      0.030368   \n",
      "\n",
      "    std_score_time  std_test_score  std_train_score  \n",
      "0     4.718199e-04        0.008971         0.013116  \n",
      "1     4.715951e-04        0.116459         0.004797  \n",
      "2     0.000000e+00        0.091888         0.006882  \n",
      "3     4.721571e-04        0.010507         0.024236  \n",
      "4     4.715951e-04        0.034964         0.007306  \n",
      "5     0.000000e+00        0.019325         0.005706  \n",
      "6     4.717075e-04        0.034932         0.007289  \n",
      "7     4.715951e-04        0.176438         0.012572  \n",
      "8     4.715951e-04        0.049344         0.008058  \n",
      "9     0.000000e+00        0.009297         0.015125  \n",
      "10    4.717076e-04        0.500271         0.001778  \n",
      "11    4.716514e-04        0.009292         0.015126  \n",
      "12    0.000000e+00        0.386423         0.005092  \n",
      "13    4.718199e-04        0.279259         0.000001  \n",
      "14    0.000000e+00        0.038918         0.007597  \n",
      "15    4.715951e-04        0.468146         0.001584  \n",
      "16    4.719324e-04        0.009305         0.015134  \n",
      "17    0.000000e+00        0.033625         0.029340  \n",
      "18    4.718199e-04        0.005602         0.007029  \n",
      "19    1.123916e-07        0.221866         0.000002  \n",
      "20    4.717076e-04        0.032744         0.026208  \n",
      "21    4.718199e-04        0.005524         0.007130  \n",
      "22    4.718199e-04        0.320227         0.000034  \n",
      "23    0.000000e+00        0.250299         0.008698  \n",
      "24    4.715953e-04        0.289018         0.000379  \n",
      "25    4.715951e-04        0.014824         0.020469  \n",
      "26    4.717075e-04        0.032785         0.026230  \n",
      "27    4.717075e-04        0.174155         0.032772  \n",
      "28    4.718199e-04        0.259832         0.000645  \n",
      "29    4.718761e-04        0.035902         0.017183  \n"
     ]
    }
   ],
   "source": [
    "cv_result = pd.DataFrame(rs.cv_results_)\n",
    "print(cv_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline-Search 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 알고리즘에도 Hyper-parameter가 있지만 Preprocessing에도 있습니다. 가령 MinMaxScaler는 minimum과 maximum을 어떻게 설정할지 정할 수 있습니다. 차원을 축소하는 PCA에서는 차원을 얼마로 축소할지 결정하는 것이 hyper-parameter 중 하나입니다. \n",
    "\n",
    "Preprocessing에서 사용하는 hyper-parameter는 학습에서 사용하는 hyper-parameter와 결합되어서 최적화 해야 합니다. 전체 Workflow를 최적화해야 하는 것이죠. \n",
    "\n",
    "Pipeline과 GridSearchCV, RandomizedSearchCV를 결합해서 사용하면 가능합니다. `Pipeline` Tutorial에서 pipeline으로 구성하면 하나의 operator처럼 동작한다고 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.403329016652\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "x, y =load_diabetes(return_X_y=True)\n",
    "y = np.reshape(y, (-1, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_scaled = y_scaler.fit_transform(y)  # y는 미리 scaling 합니다. y scaling은 pipeline에 넣지 않습니다. \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_scaled, random_state=1)\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "pca = PCA()  # PCA instance를 만듭니다. 본 예제에서 PCA는 큰 효과를 주지 않지만 예시를 위해 추가했습니다. \n",
    "\n",
    "regressor = MLPRegressor(max_iter=3000, random_state=2)  # Multi-layer perceptron을 정의합니다.\n",
    "\n",
    "steps = [('scaler', x_scaler), ('pca', pca), ('regressor', regressor)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "param_dist = {'scaler__feature_range': [(-1, 1), (0, 1)],\n",
    "              'pca__n_components': randint(7, x_train.shape[1]+1),\n",
    "              'regressor__hidden_layer_sizes': [(n_node,) for n_node in range(5, 31)],\n",
    "              'regressor__solver': ['adam', 'lbfgs'],\n",
    "              'regressor__alpha': uniform(0.0001, 0.005),\n",
    "              'regressor__max_iter': randint(1000, 5001),\n",
    "              } # parameter를 흔들 space를 정의합니다. step 이름과 parameter 이름을 '__'로 붙입니다. \n",
    "\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=pipeline, \n",
    "                        param_distributions=param_dist, \n",
    "                        n_iter=50,\n",
    "                        cv=KFold(shuffle=True), \n",
    "                        refit=True,\n",
    "                        random_state=3)  # Random Search를 initialization 합니다.\n",
    "rs.fit(x_train, y_train.ravel())  # hyper-parameter를 흔들어가며 최적의 hyper-parameter를 찾습니다. refit=True이기 때문에 찾은 모델에 대해 전체 데이터로 다시 학습합니다.  \n",
    "score = rs.score(x_test, y_test.ravel())  # Test score를 계산해봅니다. \n",
    "print('Score:', score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__alpha': 0.0045886851489163301, 'scaler__feature_range': (0, 1), 'regressor__solver': 'adam', 'regressor__max_iter': 2023, 'pca__n_components': 10, 'regressor__hidden_layer_sizes': (9,)}\n"
     ]
    }
   ],
   "source": [
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline 내부의 operator의 hyper-parameter에 접근하려면 조금 독특한 방법을 써야 합니다. step의 이름과 해당 opeartor의 hyper-parameter를 underscore 두개 '\\_\\_'로 연결해야 합니다. param_distribution에 입력할 때도 동일하게 입력해야 합니다. 다른 건 operator 한 개에 대한 예시와 동일합니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline과 Model Search 기능을 잘 사용하면 성능이 높은 Workflow를 손쉽게 만들 수 있습니다. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
